[32m[1125 18:04:17 @logger.py:73][0m Argv: run.py --task 1 --gpu 0
[32m[1125 18:04:48 @parallel.py:190][0m [MultiProcessPrefetchData] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.
[32m[1125 18:04:48 @argtools.py:146][0m [5m[31mWRN[0m Install python-prctl so that processes can be cleaned with guarantee.
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] ModelDescBase._get_inputs() interface will be deprecated after 30 Mar. Use inputs() instead!
[32m[1125 18:05:21 @trainers.py:52][0m Building graph for a single training tower ...
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] ModelDescBase._build_graph() interface will be deprecated after 30 Mar. Use build_graph() instead!
[32m[1125 18:05:21 @registry.py:121][0m conv0 input: [None, 64, 64, 3]
[32m[1125 18:05:21 @registry.py:129][0m conv0 output: [None, 56, 56, 10]
[32m[1125 18:05:21 @registry.py:121][0m pool0 input: [None, 56, 56, 10]
[32m[1125 18:05:21 @registry.py:129][0m pool0 output: [None, 8, 8, 10]
[32m[1125 18:05:21 @registry.py:121][0m fc0 input: [None, 8, 8, 10]
[32m[1125 18:05:21 @registry.py:129][0m fc0 output: [None, 15]
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] get_cost() and self.cost will be deprecated after 30 Mar. Return the cost tensor directly in build_graph() instead!
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] get_scalar_var [run.py:221] will be deprecated after 01 Aug. Simply use tf.get_variable instead!
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] ModelDescBase._get_optimizer() interface will be deprecated after 30 Mar. Use optimizer() instead!
[32m[1125 18:05:21 @model_utils.py:64][0m [36mTrainable Variables: 
[0mname       shape            dim
---------  -------------  -----
conv0/W:0  [9, 9, 3, 10]   2430
conv0/b:0  [10]              10
fc0/W:0    [640, 15]       9600
fc0/b:0    [15]              15[36m
Total #vars=4, #params=12055, size=0.05MB[0m
[32m[1125 18:05:21 @base.py:209][0m Setup callbacks graph ...
[32m[1125 18:05:21 @inference_runner.py:154][0m [InferenceRunner] Building tower 'InferenceTower' on device /gpu:0 ...
[32m[1125 18:05:21 @develop.py:99][0m [5m[31mWRN[0m [Deprecated] ModelDescBase._build_graph() interface will be deprecated after 30 Mar. Use build_graph() instead!
[32m[1125 18:05:21 @summary.py:38][0m Maintain moving average summary of 2 tensors in collection MOVING_SUMMARY_OPS.
[32m[1125 18:05:21 @summary.py:75][0m Summarizing collection 'summaries' of size 3.
[32m[1125 18:05:21 @base.py:227][0m Creating the session ...
[32m[1125 18:05:25 @base.py:233][0m Initializing the session ...
[32m[1125 18:05:25 @base.py:240][0m Graph Finalized.
[32m[1125 18:05:25 @inference_runner.py:101][0m [InferenceRunner] Will eval 30 iterations
[32m[1125 18:05:25 @monitor.py:344][0m [5m[31mWRN[0m History epoch=30 from JSON is not the predecessor of the current starting_epoch=1
[32m[1125 18:05:25 @monitor.py:345][0m [5m[31mWRN[0m If you want to resume old training, either use `AutoResumeTrainConfig` or correctly set the new starting_epoch yourself to avoid inconsistency. 
[32m[1125 18:05:25 @monitor.py:352][0m [5m[31mWRN[0m Now, we will train with starting_epoch=1 and backup old json to train_log/run/stats.json.1125-180525
[32m[1125 18:05:25 @base.py:272][0m Start Epoch 1 ...
[32m[1125 18:05:32 @base.py:282][0m Epoch 1 (global_step 30) finished, time:6.28 seconds.
[32m[1125 18:05:32 @saver.py:77][0m Model saved to train_log/run/model-30.
[32m[1125 18:05:32 @monitor.py:459][0m cross_entropy_loss: 2.7306
[32m[1125 18:05:32 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:32 @monitor.py:459][0m train_error: 0.90254
[32m[1125 18:05:32 @monitor.py:459][0m validation_cost: 2.6872
[32m[1125 18:05:32 @monitor.py:459][0m validation_error: 0.888
[32m[1125 18:05:32 @base.py:272][0m Start Epoch 2 ...
[32m[1125 18:05:32 @base.py:282][0m Epoch 2 (global_step 60) finished, time:0.318 second.
[32m[1125 18:05:32 @saver.py:77][0m Model saved to train_log/run/model-60.
[32m[1125 18:05:33 @monitor.py:459][0m cross_entropy_loss: 2.6738
[32m[1125 18:05:33 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:33 @monitor.py:459][0m train_error: 0.88513
[32m[1125 18:05:33 @monitor.py:459][0m validation_cost: 2.6601
[32m[1125 18:05:33 @monitor.py:459][0m validation_error: 0.88667
[32m[1125 18:05:33 @base.py:272][0m Start Epoch 3 ...
[32m[1125 18:05:33 @base.py:282][0m Epoch 3 (global_step 90) finished, time:0.317 second.
[32m[1125 18:05:33 @saver.py:77][0m Model saved to train_log/run/model-90.
[32m[1125 18:05:34 @monitor.py:459][0m cross_entropy_loss: 2.6472
[32m[1125 18:05:34 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:34 @monitor.py:459][0m train_error: 0.86402
[32m[1125 18:05:34 @monitor.py:459][0m validation_cost: 2.6294
[32m[1125 18:05:34 @monitor.py:459][0m validation_error: 0.86333
[32m[1125 18:05:34 @base.py:272][0m Start Epoch 4 ...
[32m[1125 18:05:34 @base.py:282][0m Epoch 4 (global_step 120) finished, time:0.321 second.
[32m[1125 18:05:34 @saver.py:77][0m Model saved to train_log/run/model-120.
[32m[1125 18:05:34 @monitor.py:459][0m cross_entropy_loss: 2.6043
[32m[1125 18:05:34 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:34 @monitor.py:459][0m train_error: 0.83627
[32m[1125 18:05:34 @monitor.py:459][0m validation_cost: 2.6089
[32m[1125 18:05:34 @monitor.py:459][0m validation_error: 0.87667
[32m[1125 18:05:34 @base.py:272][0m Start Epoch 5 ...
[32m[1125 18:05:35 @base.py:282][0m Epoch 5 (global_step 150) finished, time:0.317 second.
[32m[1125 18:05:35 @saver.py:77][0m Model saved to train_log/run/model-150.
[32m[1125 18:05:35 @monitor.py:459][0m cross_entropy_loss: 2.5658
[32m[1125 18:05:35 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:35 @monitor.py:459][0m train_error: 0.8206
[32m[1125 18:05:35 @monitor.py:459][0m validation_cost: 2.5689
[32m[1125 18:05:35 @monitor.py:459][0m validation_error: 0.84333
[32m[1125 18:05:35 @base.py:272][0m Start Epoch 6 ...
[32m[1125 18:05:35 @base.py:282][0m Epoch 6 (global_step 180) finished, time:0.317 second.
[32m[1125 18:05:38 @saver.py:77][0m Model saved to train_log/run/model-180.
[32m[1125 18:05:38 @monitor.py:459][0m cross_entropy_loss: 2.5406
[32m[1125 18:05:38 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:38 @monitor.py:459][0m train_error: 0.81675
[32m[1125 18:05:38 @monitor.py:459][0m validation_cost: 2.5353
[32m[1125 18:05:38 @monitor.py:459][0m validation_error: 0.826
[32m[1125 18:05:38 @base.py:272][0m Start Epoch 7 ...
[32m[1125 18:05:38 @base.py:282][0m Epoch 7 (global_step 210) finished, time:0.368 second.
[32m[1125 18:05:40 @saver.py:77][0m Model saved to train_log/run/model-210.
[32m[1125 18:05:40 @monitor.py:459][0m cross_entropy_loss: 2.4977
[32m[1125 18:05:40 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:40 @monitor.py:459][0m train_error: 0.792
[32m[1125 18:05:40 @monitor.py:459][0m validation_cost: 2.5082
[32m[1125 18:05:40 @monitor.py:459][0m validation_error: 0.79133
[32m[1125 18:05:40 @base.py:272][0m Start Epoch 8 ...
[32m[1125 18:05:41 @base.py:282][0m Epoch 8 (global_step 240) finished, time:0.318 second.
[32m[1125 18:05:41 @saver.py:77][0m Model saved to train_log/run/model-240.
[32m[1125 18:05:41 @monitor.py:459][0m cross_entropy_loss: 2.4404
[32m[1125 18:05:41 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:41 @monitor.py:459][0m train_error: 0.77661
[32m[1125 18:05:41 @monitor.py:459][0m validation_cost: 2.4731
[32m[1125 18:05:41 @monitor.py:459][0m validation_error: 0.78733
[32m[1125 18:05:41 @base.py:272][0m Start Epoch 9 ...
[32m[1125 18:05:41 @base.py:282][0m Epoch 9 (global_step 270) finished, time:0.318 second.
[32m[1125 18:05:41 @saver.py:77][0m Model saved to train_log/run/model-270.
[32m[1125 18:05:42 @monitor.py:459][0m cross_entropy_loss: 2.4105
[32m[1125 18:05:42 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:42 @monitor.py:459][0m train_error: 0.76857
[32m[1125 18:05:42 @monitor.py:459][0m validation_cost: 2.4249
[32m[1125 18:05:42 @monitor.py:459][0m validation_error: 0.776
[32m[1125 18:05:42 @base.py:272][0m Start Epoch 10 ...
[32m[1125 18:05:42 @base.py:282][0m Epoch 10 (global_step 300) finished, time:0.317 second.
[32m[1125 18:05:42 @saver.py:77][0m Model saved to train_log/run/model-300.
[32m[1125 18:05:45 @monitor.py:459][0m cross_entropy_loss: 2.3645
[32m[1125 18:05:45 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:45 @monitor.py:459][0m train_error: 0.74564
[32m[1125 18:05:45 @monitor.py:459][0m validation_cost: 2.4043
[32m[1125 18:05:45 @monitor.py:459][0m validation_error: 0.78267
[32m[1125 18:05:45 @base.py:272][0m Start Epoch 11 ...
[32m[1125 18:05:45 @base.py:282][0m Epoch 11 (global_step 330) finished, time:0.314 second.
[32m[1125 18:05:45 @saver.py:77][0m Model saved to train_log/run/model-330.
[32m[1125 18:05:46 @monitor.py:459][0m cross_entropy_loss: 2.341
[32m[1125 18:05:46 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:46 @monitor.py:459][0m train_error: 0.73597
[32m[1125 18:05:46 @monitor.py:459][0m validation_cost: 2.3819
[32m[1125 18:05:46 @monitor.py:459][0m validation_error: 0.78067
[32m[1125 18:05:46 @base.py:272][0m Start Epoch 12 ...
[32m[1125 18:05:46 @base.py:282][0m Epoch 12 (global_step 360) finished, time:0.318 second.
[32m[1125 18:05:50 @saver.py:77][0m Model saved to train_log/run/model-360.
[32m[1125 18:05:50 @monitor.py:459][0m cross_entropy_loss: 2.2731
[32m[1125 18:05:50 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:50 @monitor.py:459][0m train_error: 0.72023
[32m[1125 18:05:50 @monitor.py:459][0m validation_cost: 2.3484
[32m[1125 18:05:50 @monitor.py:459][0m validation_error: 0.74933
[32m[1125 18:05:50 @group.py:48][0m Callbacks took 4.144 sec in total. ModelSaver: 3.75 seconds
[32m[1125 18:05:50 @base.py:272][0m Start Epoch 13 ...
[32m[1125 18:05:51 @base.py:282][0m Epoch 13 (global_step 390) finished, time:0.367 second.
[32m[1125 18:05:51 @saver.py:77][0m Model saved to train_log/run/model-390.
[32m[1125 18:05:51 @monitor.py:459][0m cross_entropy_loss: 2.2414
[32m[1125 18:05:51 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:51 @monitor.py:459][0m train_error: 0.71502
[32m[1125 18:05:51 @monitor.py:459][0m validation_cost: 2.3256
[32m[1125 18:05:51 @monitor.py:459][0m validation_error: 0.75933
[32m[1125 18:05:51 @base.py:272][0m Start Epoch 14 ...
[32m[1125 18:05:51 @base.py:282][0m Epoch 14 (global_step 420) finished, time:0.318 second.
[32m[1125 18:05:56 @saver.py:77][0m Model saved to train_log/run/model-420.
[32m[1125 18:05:56 @monitor.py:459][0m cross_entropy_loss: 2.2125
[32m[1125 18:05:56 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:56 @monitor.py:459][0m train_error: 0.70492
[32m[1125 18:05:56 @monitor.py:459][0m validation_cost: 2.2901
[32m[1125 18:05:56 @monitor.py:459][0m validation_error: 0.75133
[32m[1125 18:05:56 @group.py:48][0m Callbacks took 4.670 sec in total. ModelSaver: 4.22 seconds
[32m[1125 18:05:56 @base.py:272][0m Start Epoch 15 ...
[32m[1125 18:05:56 @base.py:282][0m Epoch 15 (global_step 450) finished, time:0.319 second.
[32m[1125 18:05:57 @saver.py:77][0m Model saved to train_log/run/model-450.
[32m[1125 18:05:58 @monitor.py:459][0m cross_entropy_loss: 2.1799
[32m[1125 18:05:58 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:05:58 @monitor.py:459][0m train_error: 0.70446
[32m[1125 18:05:58 @monitor.py:459][0m validation_cost: 2.2761
[32m[1125 18:05:58 @monitor.py:459][0m validation_error: 0.718
[32m[1125 18:05:58 @base.py:272][0m Start Epoch 16 ...
[32m[1125 18:05:59 @base.py:282][0m Epoch 16 (global_step 480) finished, time:0.315 second.
[32m[1125 18:05:59 @saver.py:77][0m Model saved to train_log/run/model-480.
[32m[1125 18:06:02 @monitor.py:459][0m cross_entropy_loss: 2.1512
[32m[1125 18:06:02 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:02 @monitor.py:459][0m train_error: 0.68218
[32m[1125 18:06:02 @monitor.py:459][0m validation_cost: 2.3247
[32m[1125 18:06:02 @monitor.py:459][0m validation_error: 0.75333
[32m[1125 18:06:02 @base.py:272][0m Start Epoch 17 ...
[32m[1125 18:06:02 @base.py:282][0m Epoch 17 (global_step 510) finished, time:0.318 second.
[32m[1125 18:06:02 @saver.py:77][0m Model saved to train_log/run/model-510.
[32m[1125 18:06:05 @monitor.py:459][0m cross_entropy_loss: 2.1161
[32m[1125 18:06:05 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:05 @monitor.py:459][0m train_error: 0.67428
[32m[1125 18:06:05 @monitor.py:459][0m validation_cost: 2.2481
[32m[1125 18:06:05 @monitor.py:459][0m validation_error: 0.72133
[32m[1125 18:06:05 @base.py:272][0m Start Epoch 18 ...
[32m[1125 18:06:05 @base.py:282][0m Epoch 18 (global_step 540) finished, time:0.321 second.
[32m[1125 18:06:08 @saver.py:77][0m Model saved to train_log/run/model-540.
[32m[1125 18:06:08 @monitor.py:459][0m cross_entropy_loss: 2.0831
[32m[1125 18:06:08 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:08 @monitor.py:459][0m train_error: 0.65702
[32m[1125 18:06:08 @monitor.py:459][0m validation_cost: 2.2172
[32m[1125 18:06:08 @monitor.py:459][0m validation_error: 0.71733
[32m[1125 18:06:08 @group.py:48][0m Callbacks took 3.154 sec in total. ModelSaver: 2.78 seconds
[32m[1125 18:06:08 @base.py:272][0m Start Epoch 19 ...
[32m[1125 18:06:09 @base.py:282][0m Epoch 19 (global_step 570) finished, time:0.319 second.
[32m[1125 18:06:10 @saver.py:77][0m Model saved to train_log/run/model-570.
[32m[1125 18:06:11 @monitor.py:459][0m cross_entropy_loss: 2.0717
[32m[1125 18:06:11 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:11 @monitor.py:459][0m train_error: 0.6649
[32m[1125 18:06:11 @monitor.py:459][0m validation_cost: 2.3257
[32m[1125 18:06:11 @monitor.py:459][0m validation_error: 0.734
[32m[1125 18:06:11 @base.py:272][0m Start Epoch 20 ...
[32m[1125 18:06:11 @base.py:282][0m Epoch 20 (global_step 600) finished, time:0.317 second.
[32m[1125 18:06:12 @saver.py:77][0m Model saved to train_log/run/model-600.
[32m[1125 18:06:13 @monitor.py:459][0m cross_entropy_loss: 2.0492
[32m[1125 18:06:13 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:13 @monitor.py:459][0m train_error: 0.65238
[32m[1125 18:06:13 @monitor.py:459][0m validation_cost: 2.1904
[32m[1125 18:06:13 @monitor.py:459][0m validation_error: 0.70067
[32m[1125 18:06:13 @base.py:272][0m Start Epoch 21 ...
[32m[1125 18:06:13 @base.py:282][0m Epoch 21 (global_step 630) finished, time:0.317 second.
[32m[1125 18:06:13 @saver.py:77][0m Model saved to train_log/run/model-630.
[32m[1125 18:06:13 @monitor.py:459][0m cross_entropy_loss: 1.9916
[32m[1125 18:06:13 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:13 @monitor.py:459][0m train_error: 0.62197
[32m[1125 18:06:13 @monitor.py:459][0m validation_cost: 2.157
[32m[1125 18:06:13 @monitor.py:459][0m validation_error: 0.69067
[32m[1125 18:06:13 @base.py:272][0m Start Epoch 22 ...
[32m[1125 18:06:14 @base.py:282][0m Epoch 22 (global_step 660) finished, time:0.319 second.
[32m[1125 18:06:18 @saver.py:77][0m Model saved to train_log/run/model-660.
[32m[1125 18:06:18 @monitor.py:459][0m cross_entropy_loss: 1.9891
[32m[1125 18:06:18 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:18 @monitor.py:459][0m train_error: 0.61285
[32m[1125 18:06:18 @monitor.py:459][0m validation_cost: 2.1787
[32m[1125 18:06:18 @monitor.py:459][0m validation_error: 0.69133
[32m[1125 18:06:18 @group.py:48][0m Callbacks took 4.278 sec in total. ModelSaver: 3.93 seconds
[32m[1125 18:06:18 @base.py:272][0m Start Epoch 23 ...
[32m[1125 18:06:18 @base.py:282][0m Epoch 23 (global_step 690) finished, time:0.319 second.
[32m[1125 18:06:22 @saver.py:77][0m Model saved to train_log/run/model-690.
[32m[1125 18:06:22 @monitor.py:459][0m cross_entropy_loss: 1.946
[32m[1125 18:06:22 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:22 @monitor.py:459][0m train_error: 0.62078
[32m[1125 18:06:22 @monitor.py:459][0m validation_cost: 2.1577
[32m[1125 18:06:22 @monitor.py:459][0m validation_error: 0.69667
[32m[1125 18:06:22 @group.py:48][0m Callbacks took 3.632 sec in total. ModelSaver: 3.23 seconds
[32m[1125 18:06:22 @base.py:272][0m Start Epoch 24 ...
[32m[1125 18:06:22 @base.py:282][0m Epoch 24 (global_step 720) finished, time:0.367 second.
[32m[1125 18:06:26 @saver.py:77][0m Model saved to train_log/run/model-720.
[32m[1125 18:06:26 @monitor.py:459][0m cross_entropy_loss: 1.9311
[32m[1125 18:06:26 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:26 @monitor.py:459][0m train_error: 0.61549
[32m[1125 18:06:26 @monitor.py:459][0m validation_cost: 2.1077
[32m[1125 18:06:26 @monitor.py:459][0m validation_error: 0.67067
[32m[1125 18:06:26 @group.py:48][0m Callbacks took 4.016 sec in total. ModelSaver: 3.55 seconds
[32m[1125 18:06:26 @base.py:272][0m Start Epoch 25 ...
[32m[1125 18:06:27 @base.py:282][0m Epoch 25 (global_step 750) finished, time:0.317 second.
[32m[1125 18:06:29 @saver.py:77][0m Model saved to train_log/run/model-750.
[32m[1125 18:06:31 @monitor.py:459][0m cross_entropy_loss: 1.919
[32m[1125 18:06:31 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:31 @monitor.py:459][0m train_error: 0.60042
[32m[1125 18:06:31 @monitor.py:459][0m validation_cost: 2.1312
[32m[1125 18:06:31 @monitor.py:459][0m validation_error: 0.69467
[32m[1125 18:06:31 @group.py:48][0m Callbacks took 4.810 sec in total. ModelSaver: 2.27 seconds; JSONWriter: 2.22 seconds
[32m[1125 18:06:31 @base.py:272][0m Start Epoch 26 ...
[32m[1125 18:06:32 @base.py:282][0m Epoch 26 (global_step 780) finished, time:0.317 second.
[32m[1125 18:06:32 @saver.py:77][0m Model saved to train_log/run/model-780.
[32m[1125 18:06:35 @monitor.py:459][0m cross_entropy_loss: 1.891
[32m[1125 18:06:35 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:35 @monitor.py:459][0m train_error: 0.58946
[32m[1125 18:06:35 @monitor.py:459][0m validation_cost: 2.0928
[32m[1125 18:06:35 @monitor.py:459][0m validation_error: 0.682
[32m[1125 18:06:35 @group.py:48][0m Callbacks took 3.437 sec in total. JSONWriter: 2.91 seconds
[32m[1125 18:06:35 @base.py:272][0m Start Epoch 27 ...
[32m[1125 18:06:36 @base.py:282][0m Epoch 27 (global_step 810) finished, time:0.314 second.
[32m[1125 18:06:36 @saver.py:77][0m Model saved to train_log/run/model-810.
[32m[1125 18:06:38 @monitor.py:459][0m cross_entropy_loss: 1.8431
[32m[1125 18:06:38 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:38 @monitor.py:459][0m train_error: 0.58425
[32m[1125 18:06:38 @monitor.py:459][0m validation_cost: 2.1052
[32m[1125 18:06:38 @monitor.py:459][0m validation_error: 0.67333
[32m[1125 18:06:38 @base.py:272][0m Start Epoch 28 ...
[32m[1125 18:06:38 @base.py:282][0m Epoch 28 (global_step 840) finished, time:0.316 second.
[32m[1125 18:06:39 @saver.py:77][0m Model saved to train_log/run/model-840.
[32m[1125 18:06:40 @monitor.py:459][0m cross_entropy_loss: 1.8133
[32m[1125 18:06:40 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:40 @monitor.py:459][0m train_error: 0.57805
[32m[1125 18:06:40 @monitor.py:459][0m validation_cost: 2.0626
[32m[1125 18:06:40 @monitor.py:459][0m validation_error: 0.67333
[32m[1125 18:06:40 @base.py:272][0m Start Epoch 29 ...
[32m[1125 18:06:41 @base.py:282][0m Epoch 29 (global_step 870) finished, time:0.316 second.
[32m[1125 18:06:41 @saver.py:77][0m Model saved to train_log/run/model-870.
[32m[1125 18:06:43 @monitor.py:459][0m cross_entropy_loss: 1.7967
[32m[1125 18:06:43 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:43 @monitor.py:459][0m train_error: 0.56227
[32m[1125 18:06:43 @monitor.py:459][0m validation_cost: 2.0803
[32m[1125 18:06:43 @monitor.py:459][0m validation_error: 0.67133
[32m[1125 18:06:43 @base.py:272][0m Start Epoch 30 ...
[32m[1125 18:06:44 @base.py:282][0m Epoch 30 (global_step 900) finished, time:0.317 second.
[32m[1125 18:06:44 @saver.py:77][0m Model saved to train_log/run/model-900.
[32m[1125 18:06:46 @monitor.py:459][0m cross_entropy_loss: 1.7877
[32m[1125 18:06:46 @monitor.py:459][0m learning_rate: 0.01
[32m[1125 18:06:46 @monitor.py:459][0m train_error: 0.56365
[32m[1125 18:06:46 @monitor.py:459][0m validation_cost: 2.0386
[32m[1125 18:06:46 @monitor.py:459][0m validation_error: 0.652
[32m[1125 18:06:46 @base.py:286][0m Training has finished!
